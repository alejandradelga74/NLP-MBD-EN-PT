{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
<<<<<<< Updated upstream
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acastellanos-ie/NLP-MBD-EN-PT/blob/main/tagging_parsing_practice/bag_of_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
=======
>>>>>>> Stashed changes
        "id": "LCvwbQnTvBRh"
      },
      "source": [
        "# Google Colab Configuration\n",
        "\n",
        "**Execute this steps to configure the Google Colab environment in order to execute this notebook. It is not required if you are executing it locally and you have properly configured your local environment according to what explained in the Github Repository.**\n",
        "\n",
        "The first step is to clone the repository to have access to all the data and files"
      ]
    },
    {
      "cell_type": "code",
<<<<<<< Updated upstream
      "source": [
        "repository_name = \"NLP-MBD-EN-PT\"\n",
        "repository_url = 'https://github.com/acastellanos-ie/' + repository_name"
      ],
      "metadata": {
        "id": "gakj_n0h70ox"
      },
      "execution_count": 1,
      "outputs": []
=======
      "execution_count": 1,
      "metadata": {
        "id": "gakj_n0h70ox"
      },
      "outputs": [],
      "source": [
        "repository_name = \"NLP-MBD-EN-PT\"\n",
        "repository_url = 'https://github.com/alejandradelga74/' + repository_name"
      ]
>>>>>>> Stashed changes
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
<<<<<<< Updated upstream
        "id": "3d7mC64KvlwP",
        "outputId": "13cb1328-b3f5-4904-d0eb-971601eed03d",
=======
>>>>>>> Stashed changes
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d7mC64KvlwP",
        "outputId": "e5cb877b-fee1-4be7-f1bf-343f2fba42a7"
      },
      "outputs": [],
      "source": [
<<<<<<< Updated upstream
        "! git clone $repository_url"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'NLP-MBD-EN-PT' already exists and is not an empty directory.\n"
          ]
        }
=======
        "# ! git clone $repository_url"
>>>>>>> Stashed changes
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ecfec2Y4v6e9"
      },
      "source": [
        "Install the requirements"
      ]
    },
    {
<<<<<<< Updated upstream
=======
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIep7l0jvtUB",
        "outputId": "d45eba5a-9325-44ed-ae93-ebf4493fa51a"
      },
      "outputs": [],
      "source": [
        "# ! pip install -Uqqr $repository_name/requirements.txt"
      ]
    },
    {
>>>>>>> Stashed changes
      "cell_type": "markdown",
      "metadata": {
        "id": "JHDzMQwpyODo"
      },
      "source": [
        "Now you have everything you need to execute the code in Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeGC-Qg3sK8Y"
      },
      "source": [
        "# Bag-of-words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< Updated upstream
        "outputId": "1ca40e74-c3f3-4803-8a92-340652fc9d2f"
=======
        "id": "r_8zOo4gsK8f",
        "outputId": "1fb851ee-be89-4f1d-aca0-e42004a3ca72"
>>>>>>> Stashed changes
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package shakespeare to\n",
            "[nltk_data]     /ec/remote/home/delgmar/nltk_data...\n",
            "[nltk_data]   Package shakespeare is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /ec/remote/home/delgmar/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('shakespeare')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np"
<<<<<<< Updated upstream
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]   Package shakespeare is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
=======
>>>>>>> Stashed changes
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onkwLfBQsK8g"
      },
      "source": [
        "The `nltk` library includes several corpus for experimentation. In this markdown we are going to make use of the corpus including the set of Shakespeare's plays.\n",
        "\n",
        "In the following cell, I will load the corpus and create a dataframe with the name of the book and the textual content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< Updated upstream
        "outputId": "86c4ef5f-182d-4950-e1dc-05549b20e668"
      },
      "source": [
        "shakespeare_df = pd.DataFrame(columns=[\"book\", \"words\"])\n",
        "for ii, book in enumerate(nltk.corpus.shakespeare.fileids()):\n",
        "    shakespeare_df.loc[ii] = (book, \" \".join(nltk.corpus.shakespeare.words(book)))\n",
        "print(shakespeare_df)"
      ],
      "execution_count": 4,
=======
        "id": "pFhGK1uasK8h",
        "outputId": "f23b209c-859f-4cae-aa0b-65202db6add0"
      },
>>>>>>> Stashed changes
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           book                                              words\n",
            "0   a_and_c.xml  The Tragedy of Antony and Cleopatra Dramatis P...\n",
            "1     dream.xml  A Midsummer Night ' s Dream Dramatis Personae ...\n",
            "2    hamlet.xml  The Tragedy of Hamlet , Prince of Denmark Dram...\n",
            "3  j_caesar.xml  The Tragedy of Julius Caesar Dramatis Personae...\n",
            "4   macbeth.xml  The Tragedy of Macbeth Dramatis Personae DUNCA...\n",
            "5  merchant.xml  The Merchant of Venice Dramatis Personae The D...\n",
            "6   othello.xml  The Tragedy of Othello , the Moor of Venice Dr...\n",
            "7   r_and_j.xml  The Tragedy of Romeo and Juliet Text placed in...\n"
          ]
        }
      ],
      "source": [
        "shakespeare_df = pd.DataFrame(columns=[\"book\", \"words\"])\n",
        "for ii, book in enumerate(nltk.corpus.shakespeare.fileids()):\n",
        "    shakespeare_df.loc[ii] = (book, \" \".join(nltk.corpus.shakespeare.words(book)))\n",
        "print(shakespeare_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xgnNtVnsK8i"
      },
      "source": [
        "While this representation can be useful for humans, it is of no use if you want to use these data for an NLP system.\n",
        "\n",
        "As we discussed in class, we need to create the document-term matrix which will be the input for any NLP system we need to create on top of it. In the document term matrix we have a row for each one of the different documents (the Shakespeare's plays) and a column for each one of the words in the dataset. At each cell, you will find the weight of the word in the document (for example, how many times does the word appear in the document).\n",
        "\n",
        "In class we presented several weighting approaches, let's see how we can create them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdJiO9XvsK8i"
      },
      "source": [
        "Let's start with the simplest one: The Binary weighting. Binary weighting only defines if a word appears (1) or does not appear (0) in a document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< Updated upstream
        "outputId": "3c9f51c9-4fff-490b-c45d-a9b3f58f731a"
=======
        "id": "Jg_NgZWysK8j",
        "outputId": "b10aa454-9623-4ae3-d8a3-187d83da3a2f"
>>>>>>> Stashed changes
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   1992  1996  1998  1999  abandon  abate  abatements  abbey  abhor  abhorred  \\\n",
            "0     0     0     0     0        0      0           0      0      0         0   \n",
            "1     0     0     0     0        0      1           0      0      0         0   \n",
            "2     0     0     0     0        0      1           1      0      0         1   \n",
            "3     0     0     0     0        0      0           0      0      0         0   \n",
            "4     0     0     0     0        0      0           0      0      0         1   \n",
            "5     0     0     0     0        0      1           0      0      0         0   \n",
            "6     0     0     0     0        1      0           0      0      1         0   \n",
            "7     1     1     1     1        0      1           0      1      0         1   \n",
            "\n",
            "   ...  your  yours  yourself  yourselves  youth  youthful  youths  zeal  \\\n",
            "0  ...     1      1         1           1      1         0       0     0   \n",
            "1  ...     1      1         1           1      1         0       0     0   \n",
            "2  ...     1      1         1           1      1         0       0     0   \n",
            "3  ...     1      1         1           1      0         1       1     0   \n",
            "4  ...     1      1         1           1      1         0       1     0   \n",
            "5  ...     1      1         1           0      1         1       0     1   \n",
            "6  ...     1      1         1           0      1         0       0     0   \n",
            "7  ...     1      1         1           0      1         1       0     0   \n",
            "\n",
            "   zone  zounds  \n",
            "0     0       0  \n",
            "1     0       0  \n",
            "2     1       0  \n",
            "3     0       0  \n",
            "4     0       0  \n",
            "5     0       0  \n",
            "6     0       1  \n",
            "7     0       1  \n",
            "\n",
            "[8 rows x 11316 columns]\n"
          ]
        }
      ],
      "source": [
        "binary_weighting = CountVectorizer(binary=True)\n",
        "binary_shakespeare = binary_weighting.fit_transform(shakespeare_df.words)\n",
        "binary_dt_matrix = pd.DataFrame(binary_shakespeare.A, columns=binary_weighting.get_feature_names_out())\n",
        "print(binary_dt_matrix)"
<<<<<<< Updated upstream
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   1992  1996  1998  1999  abandon  abate  abatements  abbey  abhor  abhorred  \\\n",
            "0     0     0     0     0        0      0           0      0      0         0   \n",
            "1     0     0     0     0        0      1           0      0      0         0   \n",
            "2     0     0     0     0        0      1           1      0      0         1   \n",
            "3     0     0     0     0        0      0           0      0      0         0   \n",
            "4     0     0     0     0        0      0           0      0      0         1   \n",
            "5     0     0     0     0        0      1           0      0      0         0   \n",
            "6     0     0     0     0        1      0           0      0      1         0   \n",
            "7     1     1     1     1        0      1           0      1      0         1   \n",
            "\n",
            "   ...  your  yours  yourself  yourselves  youth  youthful  youths  zeal  \\\n",
            "0  ...     1      1         1           1      1         0       0     0   \n",
            "1  ...     1      1         1           1      1         0       0     0   \n",
            "2  ...     1      1         1           1      1         0       0     0   \n",
            "3  ...     1      1         1           1      0         1       1     0   \n",
            "4  ...     1      1         1           1      1         0       1     0   \n",
            "5  ...     1      1         1           0      1         1       0     1   \n",
            "6  ...     1      1         1           0      1         0       0     0   \n",
            "7  ...     1      1         1           0      1         1       0     0   \n",
            "\n",
            "   zone  zounds  \n",
            "0     0       0  \n",
            "1     0       0  \n",
            "2     1       0  \n",
            "3     0       0  \n",
            "4     0       0  \n",
            "5     0       0  \n",
            "6     0       1  \n",
            "7     0       1  \n",
            "\n",
            "[8 rows x 11316 columns]\n"
          ]
        }
=======
>>>>>>> Stashed changes
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmEaF25isK8j"
      },
      "source": [
        "Let's inspect the most and least important terms related to the document 6 (Othello)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< Updated upstream
        "outputId": "13fe220e-9c18-4aa4-9b30-4bfd447e6024"
      },
      "source": [
        "document = 6\n",
        "print(\"25 most important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(binary_dt_matrix.iloc[:, np.argsort(binary_dt_matrix.loc[document])[::-1]].iloc[document][:25])\n",
        "\n",
        "print(\"25 least important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(binary_dt_matrix.iloc[:, np.argsort(binary_dt_matrix.loc[document])[::-1]].iloc[document][-25:])\n",
        "\n"
      ],
      "execution_count": 6,
=======
        "id": "VDXuF1qasK8k",
        "outputId": "19faff24-776d-497f-d08b-c846193e5ae2"
      },
>>>>>>> Stashed changes
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25 most important terms for document othello.xml\n",
            "zounds         1\n",
            "practiser      1\n",
            "potent         1\n",
            "potential      1\n",
            "determined     1\n",
            "determine      1\n",
            "potting        1\n",
            "pottle         1\n",
            "pour           1\n",
            "determinate    1\n",
            "poverty        1\n",
            "destruction    1\n",
            "power          1\n",
            "powerful       1\n",
            "powers         1\n",
            "pox            1\n",
            "practise       1\n",
            "potations      1\n",
            "devesting      1\n",
            "device         1\n",
            "devotion       1\n",
            "portents       1\n",
            "dew            1\n",
            "devout         1\n",
            "position       1\n",
            "Name: 6, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "document = 6\n",
        "print(\"25 most important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(binary_dt_matrix.iloc[:, np.argsort(binary_dt_matrix.loc[document])[::-1]].iloc[document][:25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25 least important terms for document othello.xml\n",
            "outrage        0\n",
            "origin         0\n",
            "orient         0\n",
            "organs         0\n",
            "organ          0\n",
            "ore            0\n",
            "ordnance       0\n",
            "osier          0\n",
            "osric          0\n",
            "ossa           0\n",
            "ostent         0\n",
            "ostentation    0\n",
            "ostents        0\n",
            "ought          0\n",
            "ounce          0\n",
            "ourself        0\n",
            "ousel          0\n",
            "outbrave       0\n",
            "outbreak       0\n",
            "outcries       0\n",
            "outcry         0\n",
            "outface        0\n",
            "outlawry       0\n",
            "outlives       0\n",
            "1992           0\n",
            "Name: 6, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"25 least important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(binary_dt_matrix.iloc[:, np.argsort(binary_dt_matrix.loc[document])[::-1]].iloc[document][-25:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKzkc_KysK8k"
      },
      "source": [
        "As you can see, the representation is not very useful as it is. By only telling us if a word appears or not in a document is not giving us a lot of information. **Can you think on a situation where this binary weighting can be sufficient?**\n",
        "\n",
        "The next thing to know will be whether the word appears only once or several times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< Updated upstream
        "outputId": "498c7e33-8b7c-4518-a365-0bd4eaed337e"
=======
        "id": "J7N3XRgdsK8l",
        "outputId": "f479b242-a47f-4caf-ea32-47a33f670beb"
>>>>>>> Stashed changes
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   1992  1996  1998  1999  abandon  abate  abatements  abbey  abhor  abhorred  \\\n",
            "0     0     0     0     0        0      0           0      0      0         0   \n",
            "1     0     0     0     0        0      1           0      0      0         0   \n",
            "2     0     0     0     0        0      1           1      0      0         1   \n",
            "3     0     0     0     0        0      0           0      0      0         0   \n",
            "4     0     0     0     0        0      0           0      0      0         1   \n",
            "5     0     0     0     0        0      1           0      0      0         0   \n",
            "6     0     0     0     0        1      0           0      0      3         0   \n",
            "7     1     1     1     1        0      1           0      1      0         1   \n",
            "\n",
            "   ...  your  yours  yourself  yourselves  youth  youthful  youths  zeal  \\\n",
            "0  ...   140     11        15           1      5         0       0     0   \n",
            "1  ...   123      4         3           3      7         0       0     0   \n",
            "2  ...   242      6        15           1     16         0       0     0   \n",
            "3  ...   130     10        12           6      0         1       1     0   \n",
            "4  ...   121      3         2           3      1         0       1     0   \n",
            "5  ...   175     16         4           0      8         1       0     1   \n",
            "6  ...   205      6        16           0      5         0       0     0   \n",
            "7  ...   103      4         5           0      6         3       0     0   \n",
            "\n",
            "   zone  zounds  \n",
            "0     0       0  \n",
            "1     0       0  \n",
            "2     1       0  \n",
            "3     0       0  \n",
            "4     0       0  \n",
            "5     0       0  \n",
            "6     0       3  \n",
            "7     0       2  \n",
            "\n",
            "[8 rows x 11316 columns]\n"
          ]
        }
      ],
      "source": [
        "tf_weighting = CountVectorizer()\n",
        "tf_shakespeare = tf_weighting.fit_transform(shakespeare_df.words)\n",
        "tf_dt_matrix = pd.DataFrame(tf_shakespeare.A, columns=tf_weighting.get_feature_names_out())\n",
        "print(tf_dt_matrix)"
<<<<<<< Updated upstream
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   1992  1996  1998  1999  abandon  abate  abatements  abbey  abhor  abhorred  \\\n",
            "0     0     0     0     0        0      0           0      0      0         0   \n",
            "1     0     0     0     0        0      1           0      0      0         0   \n",
            "2     0     0     0     0        0      1           1      0      0         1   \n",
            "3     0     0     0     0        0      0           0      0      0         0   \n",
            "4     0     0     0     0        0      0           0      0      0         1   \n",
            "5     0     0     0     0        0      1           0      0      0         0   \n",
            "6     0     0     0     0        1      0           0      0      3         0   \n",
            "7     1     1     1     1        0      1           0      1      0         1   \n",
            "\n",
            "   ...  your  yours  yourself  yourselves  youth  youthful  youths  zeal  \\\n",
            "0  ...   140     11        15           1      5         0       0     0   \n",
            "1  ...   123      4         3           3      7         0       0     0   \n",
            "2  ...   242      6        15           1     16         0       0     0   \n",
            "3  ...   130     10        12           6      0         1       1     0   \n",
            "4  ...   121      3         2           3      1         0       1     0   \n",
            "5  ...   175     16         4           0      8         1       0     1   \n",
            "6  ...   205      6        16           0      5         0       0     0   \n",
            "7  ...   103      4         5           0      6         3       0     0   \n",
            "\n",
            "   zone  zounds  \n",
            "0     0       0  \n",
            "1     0       0  \n",
            "2     1       0  \n",
            "3     0       0  \n",
            "4     0       0  \n",
            "5     0       0  \n",
            "6     0       3  \n",
            "7     0       2  \n",
            "\n",
            "[8 rows x 11316 columns]\n"
          ]
        }
=======
>>>>>>> Stashed changes
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0L566RDsK8m"
      },
      "source": [
        "Ok, now we have the words weighted according to how many times they appear in the document.\n",
        "\n",
        "Let's check now the most and least important words in Othello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< Updated upstream
        "outputId": "154e60a2-73ef-4c61-a2b1-300913c73f59"
      },
      "source": [
        "document = 6\n",
        "print(\"25 most important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(tf_dt_matrix.iloc[:, np.argsort(tf_dt_matrix.loc[document])[::-1]].iloc[document][:25])\n",
        "\n",
        "print(\"25 least important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(tf_dt_matrix.iloc[:, np.argsort(tf_dt_matrix.loc[document])[::-1]].iloc[document][-25:])"
      ],
      "execution_count": 8,
=======
        "id": "h1NAk703sK8m",
        "outputId": "a77cacd3-bec3-4c84-afe7-9fbc9c8fa170"
      },
>>>>>>> Stashed changes
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25 most important terms for document othello.xml\n",
            "and          794\n",
            "the          761\n",
            "to           629\n",
            "you          486\n",
            "of           475\n",
            "my           416\n",
            "that         395\n",
            "iago         360\n",
            "in           341\n",
            "othello      336\n",
            "not          318\n",
            "it           317\n",
            "is           309\n",
            "me           281\n",
            "cassio       254\n",
            "he           246\n",
            "for          240\n",
            "desdemona    230\n",
            "be           226\n",
            "with         221\n",
            "but          221\n",
            "this         220\n",
            "do           219\n",
            "her          215\n",
            "have         207\n",
            "Name: 6, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "document = 6\n",
        "print(\"25 most important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(tf_dt_matrix.iloc[:, np.argsort(tf_dt_matrix.loc[document])[::-1]].iloc[document][:25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25 least important terms for document othello.xml\n",
            "outrage        0\n",
            "origin         0\n",
            "orient         0\n",
            "organs         0\n",
            "organ          0\n",
            "ore            0\n",
            "ordnance       0\n",
            "osier          0\n",
            "osric          0\n",
            "ossa           0\n",
            "ostent         0\n",
            "ostentation    0\n",
            "ostents        0\n",
            "ought          0\n",
            "ounce          0\n",
            "ourself        0\n",
            "ousel          0\n",
            "outbrave       0\n",
            "outbreak       0\n",
            "outcries       0\n",
            "outcry         0\n",
            "outface        0\n",
            "outlawry       0\n",
            "outlives       0\n",
            "1992           0\n",
            "Name: 6, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"25 least important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(tf_dt_matrix.iloc[:, np.argsort(tf_dt_matrix.loc[document])[::-1]].iloc[document][-25:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFSHiEEGsK8n"
      },
      "source": [
        "**What problem do you see with the most important words? Are they really representative?**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CiGiYtasK8n"
      },
      "source": [
        "Let's check now how to create the TF-IDF weighting to see if we can improve this representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< Updated upstream
        "outputId": "debc7b5d-445f-458e-903f-8236aa4690a0"
=======
        "id": "bAfISl2jsK8o",
        "outputId": "0e56ad71-11cc-4001-8cc1-d338af82d15d"
>>>>>>> Stashed changes
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       1992      1996      1998      1999   abandon     abate  abatements  \\\n",
            "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
            "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.001132    0.000000   \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000551    0.000869   \n",
            "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
            "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
            "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000843    0.000000   \n",
            "6  0.000000  0.000000  0.000000  0.000000  0.000973  0.000000    0.000000   \n",
            "7  0.001163  0.001163  0.001163  0.001163  0.000000  0.000738    0.000000   \n",
            "\n",
            "      abbey     abhor  abhorred  ...      your     yours  yourself  \\\n",
            "0  0.000000  0.000000  0.000000  ...  0.062407  0.004903  0.006686   \n",
            "1  0.000000  0.000000  0.000000  ...  0.087673  0.002851  0.002138   \n",
            "2  0.000000  0.000000  0.000628  ...  0.083986  0.002082  0.005206   \n",
            "3  0.000000  0.000000  0.000000  ...  0.071664  0.005513  0.006615   \n",
            "4  0.000000  0.000000  0.001116  ...  0.074558  0.001849  0.001232   \n",
            "5  0.000000  0.000000  0.000000  ...  0.092911  0.008495  0.002124   \n",
            "6  0.000000  0.002918  0.000000  ...  0.079621  0.002330  0.006214   \n",
            "7  0.001163  0.000000  0.000841  ...  0.047856  0.001858  0.002323   \n",
            "\n",
            "   yourselves     youth  youthful    youths      zeal      zone    zounds  \n",
            "0    0.000627  0.002491  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "1    0.003005  0.005577  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "2    0.000488  0.006207  0.000000  0.000000  0.000000  0.000869  0.000000  \n",
            "3    0.004649  0.000000  0.000998  0.001157  0.000000  0.000000  0.000000  \n",
            "4    0.002598  0.000689  0.000000  0.001293  0.000000  0.000000  0.000000  \n",
            "5    0.000000  0.004748  0.000961  0.000000  0.001329  0.000000  0.000000  \n",
            "6    0.000000  0.002171  0.000000  0.000000  0.000000  0.000000  0.002445  \n",
            "7    0.000000  0.003116  0.002524  0.000000  0.000000  0.000000  0.001950  \n",
            "\n",
            "[8 rows x 11316 columns]\n"
          ]
        }
      ],
      "source": [
        "tf_idf_weighting = TfidfVectorizer()\n",
        "tf_idf_shakespeare = tf_idf_weighting.fit_transform(shakespeare_df.words)\n",
        "tf_idf_dt_matrix = pd.DataFrame(tf_idf_shakespeare.A, columns=tf_idf_weighting.get_feature_names_out())\n",
        "print(tf_idf_dt_matrix)"
<<<<<<< Updated upstream
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       1992      1996      1998      1999   abandon     abate  abatements  \\\n",
            "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
            "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.001132    0.000000   \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000551    0.000869   \n",
            "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
            "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
            "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.000843    0.000000   \n",
            "6  0.000000  0.000000  0.000000  0.000000  0.000973  0.000000    0.000000   \n",
            "7  0.001163  0.001163  0.001163  0.001163  0.000000  0.000738    0.000000   \n",
            "\n",
            "      abbey     abhor  abhorred  ...      your     yours  yourself  \\\n",
            "0  0.000000  0.000000  0.000000  ...  0.062407  0.004903  0.006686   \n",
            "1  0.000000  0.000000  0.000000  ...  0.087673  0.002851  0.002138   \n",
            "2  0.000000  0.000000  0.000628  ...  0.083986  0.002082  0.005206   \n",
            "3  0.000000  0.000000  0.000000  ...  0.071664  0.005513  0.006615   \n",
            "4  0.000000  0.000000  0.001116  ...  0.074558  0.001849  0.001232   \n",
            "5  0.000000  0.000000  0.000000  ...  0.092911  0.008495  0.002124   \n",
            "6  0.000000  0.002918  0.000000  ...  0.079621  0.002330  0.006214   \n",
            "7  0.001163  0.000000  0.000841  ...  0.047856  0.001858  0.002323   \n",
            "\n",
            "   yourselves     youth  youthful    youths      zeal      zone    zounds  \n",
            "0    0.000627  0.002491  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "1    0.003005  0.005577  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "2    0.000488  0.006207  0.000000  0.000000  0.000000  0.000869  0.000000  \n",
            "3    0.004649  0.000000  0.000998  0.001157  0.000000  0.000000  0.000000  \n",
            "4    0.002598  0.000689  0.000000  0.001293  0.000000  0.000000  0.000000  \n",
            "5    0.000000  0.004748  0.000961  0.000000  0.001329  0.000000  0.000000  \n",
            "6    0.000000  0.002171  0.000000  0.000000  0.000000  0.000000  0.002445  \n",
            "7    0.000000  0.003116  0.002524  0.000000  0.000000  0.000000  0.001950  \n",
            "\n",
            "[8 rows x 11316 columns]\n"
          ]
        }
=======
>>>>>>> Stashed changes
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< Updated upstream
        "outputId": "f63595bc-0dcb-42b2-89a9-f3f6fc517b4d"
      },
      "source": [
        "document = 6\n",
        "print(\"25 most important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(tf_idf_dt_matrix.iloc[:, np.argsort(tf_idf_dt_matrix.loc[document])[::-1]].iloc[document][:25])\n",
        "\n",
        "print(\"25 least important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(tf_idf_dt_matrix.iloc[:, np.argsort(tf_idf_dt_matrix.loc[document])[::-1]].iloc[document][-25:])"
      ],
      "execution_count": 10,
=======
        "id": "GEwT8UxAsK8o",
        "outputId": "122963d2-a1cf-400e-f758-d1ace3e17244"
      },
>>>>>>> Stashed changes
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25 most important terms for document othello.xml\n",
            "iago         0.350125\n",
            "othello      0.326783\n",
            "and          0.308385\n",
            "the          0.295568\n",
            "cassio       0.247033\n",
            "to           0.244300\n",
            "desdemona    0.223691\n",
            "you          0.188760\n",
            "of           0.184487\n",
            "my           0.161572\n",
            "that         0.153416\n",
            "emilia       0.134215\n",
            "in           0.132442\n",
            "not          0.123509\n",
            "it           0.123121\n",
            "is           0.120014\n",
            "me           0.109139\n",
            "roderigo     0.101147\n",
            "he           0.095545\n",
            "for          0.093215\n",
            "be           0.087777\n",
            "but          0.085835\n",
            "with         0.085835\n",
            "this         0.085447\n",
            "do           0.085058\n",
            "Name: 6, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "document = 6\n",
        "print(\"25 most important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(tf_idf_dt_matrix.iloc[:, np.argsort(tf_idf_dt_matrix.loc[document])[::-1]].iloc[document][:25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25 least important terms for document othello.xml\n",
            "outrage        0.0\n",
            "origin         0.0\n",
            "orient         0.0\n",
            "organs         0.0\n",
            "organ          0.0\n",
            "ore            0.0\n",
            "ordnance       0.0\n",
            "osier          0.0\n",
            "osric          0.0\n",
            "ossa           0.0\n",
            "ostent         0.0\n",
            "ostentation    0.0\n",
            "ostents        0.0\n",
            "ought          0.0\n",
            "ounce          0.0\n",
            "ourself        0.0\n",
            "ousel          0.0\n",
            "outbrave       0.0\n",
            "outbreak       0.0\n",
            "outcries       0.0\n",
            "outcry         0.0\n",
            "outface        0.0\n",
            "outlawry       0.0\n",
            "outlives       0.0\n",
            "1992           0.0\n",
            "Name: 6, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"25 least important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(tf_idf_dt_matrix.iloc[:, np.argsort(tf_idf_dt_matrix.loc[document])[::-1]].iloc[document][-25:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxSFxfWqsK8p"
      },
      "source": [
        "**What do you see now in the representation? Have we solved all the problems?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL1a-Y01sK8p"
      },
      "source": [
        "# StopWords\n",
        "\n",
        "In the previous section we have experimenting some problems related to stopwords, such as `and` or `of`. These words do not carry any meaning and are unlikely to provide any advantage for any subsequent NLP task and, therefore, we are safe to remove them.\n",
        "\n",
        "Let's see how to do it via NLTK.\n",
        "\n",
        "Since stopwords are language-dependant, NLTK provides a list for several languages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< Updated upstream
        "outputId": "b215f39d-c57e-4d40-e8f1-ad3b1f684bbd"
=======
        "id": "fVxZRw4dsK8p",
        "outputId": "bc157e18-de58-439e-f058-11c7c42a28e3"
>>>>>>> Stashed changes
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Languages for which NLTK provides an stopword list: arabic, azerbaijani, basque, bengali, catalan, chinese, danish, dutch, english, finnish, french, german, greek, hebrew, hinglish, hungarian, indonesian, italian, kazakh, nepali, norwegian, portuguese, romanian, russian, slovene, spanish, swedish, tajik, turkish\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "print(\"Languages for which NLTK provides an stopword list:\", \", \".join(stopwords.fileids()))"
<<<<<<< Updated upstream
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Languages for which NLTK provides an stopword list: arabic, azerbaijani, basque, bengali, catalan, chinese, danish, dutch, english, finnish, french, german, greek, hebrew, hinglish, hungarian, indonesian, italian, kazakh, nepali, norwegian, portuguese, romanian, russian, slovene, spanish, swedish, tajik, turkish\n"
          ]
        }
=======
>>>>>>> Stashed changes
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKl8SwQ8sK8q"
      },
      "source": [
        "We are just interested in the English stopword list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< Updated upstream
        "outputId": "e90afd17-d2f1-471e-fcd3-aa41f72353ac"
      },
      "source": [
        "print(\"Example of 25 English stopwords:\", \", \".join(stopwords.words(\"english\")[:25]))"
      ],
      "execution_count": 12,
=======
        "id": "qUeIICa1sK8q",
        "outputId": "ab9bb30d-f86f-4d8c-dbe2-0ac37a6b40c4"
      },
>>>>>>> Stashed changes
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example of 25 English stopwords: i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers\n"
          ]
        }
      ],
      "source": [
        "print(\"Example of 25 English stopwords:\", \", \".join(stopwords.words(\"english\")[:25]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zpkp2lisK8r"
      },
      "source": [
        "We can use this list to remove these words from our representation and create the document term matrix without them. Let's check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< Updated upstream
        "outputId": "3129663c-0d51-46f7-da07-8bb1a514d6d5"
=======
        "id": "a5XKr4U4sK8r",
        "outputId": "80675f19-6e23-4f89-c99c-4dec3990db73"
>>>>>>> Stashed changes
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       1992      1996      1998      1999   abandon     abate  abatements  \\\n",
            "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
            "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.002333    0.000000   \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.001020    0.001609   \n",
            "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
            "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
            "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.001867    0.000000   \n",
            "6  0.000000  0.000000  0.000000  0.000000  0.001506  0.000000    0.000000   \n",
            "7  0.001902  0.001902  0.001902  0.001902  0.000000  0.001206    0.000000   \n",
            "\n",
            "      abbey     abhor  abhorred  ...     young   younger  youngest   younker  \\\n",
            "0  0.000000  0.000000  0.000000  ...  0.002220  0.001340  0.000000  0.000000   \n",
            "1  0.000000  0.000000  0.000000  ...  0.010286  0.000000  0.000000  0.000000   \n",
            "2  0.000000  0.000000  0.001163  ...  0.010921  0.001163  0.000000  0.000000   \n",
            "3  0.000000  0.000000  0.000000  ...  0.009507  0.000000  0.000000  0.000000   \n",
            "4  0.000000  0.000000  0.001947  ...  0.015053  0.000000  0.000000  0.000000   \n",
            "5  0.000000  0.000000  0.000000  ...  0.028228  0.000000  0.000000  0.002945   \n",
            "6  0.000000  0.004519  0.000000  ...  0.006015  0.000000  0.000000  0.000000   \n",
            "7  0.001902  0.000000  0.001376  ...  0.018234  0.002752  0.001902  0.000000   \n",
            "\n",
            "      youth  youthful    youths      zeal      zone    zounds  \n",
            "0  0.004135  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "1  0.011497  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "2  0.011489  0.000000  0.000000  0.000000  0.001609  0.000000  \n",
            "3  0.000000  0.001722  0.001995  0.000000  0.000000  0.000000  \n",
            "4  0.001202  0.000000  0.002256  0.000000  0.000000  0.000000  \n",
            "5  0.010518  0.002130  0.000000  0.002945  0.000000  0.000000  \n",
            "6  0.003362  0.000000  0.000000  0.000000  0.000000  0.003787  \n",
            "7  0.005095  0.004128  0.000000  0.000000  0.000000  0.003189  \n",
            "\n",
            "[8 rows x 11048 columns]\n"
          ]
        }
      ],
      "source": [
        "sw_free_tf_idf_weighting = TfidfVectorizer(stop_words='english')\n",
        "sw_free_tf_idf_shakespeare = sw_free_tf_idf_weighting.fit_transform(shakespeare_df.words)\n",
        "sw_free_tf_idf_dt_matrix = pd.DataFrame(sw_free_tf_idf_shakespeare.A, columns=sw_free_tf_idf_weighting.get_feature_names_out())\n",
        "print(sw_free_tf_idf_dt_matrix)"
<<<<<<< Updated upstream
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       1992      1996      1998      1999   abandon     abate  abatements  \\\n",
            "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
            "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.002333    0.000000   \n",
            "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.001020    0.001609   \n",
            "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
            "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
            "5  0.000000  0.000000  0.000000  0.000000  0.000000  0.001867    0.000000   \n",
            "6  0.000000  0.000000  0.000000  0.000000  0.001506  0.000000    0.000000   \n",
            "7  0.001902  0.001902  0.001902  0.001902  0.000000  0.001206    0.000000   \n",
            "\n",
            "      abbey     abhor  abhorred  ...     young   younger  youngest   younker  \\\n",
            "0  0.000000  0.000000  0.000000  ...  0.002220  0.001340  0.000000  0.000000   \n",
            "1  0.000000  0.000000  0.000000  ...  0.010286  0.000000  0.000000  0.000000   \n",
            "2  0.000000  0.000000  0.001163  ...  0.010921  0.001163  0.000000  0.000000   \n",
            "3  0.000000  0.000000  0.000000  ...  0.009507  0.000000  0.000000  0.000000   \n",
            "4  0.000000  0.000000  0.001947  ...  0.015053  0.000000  0.000000  0.000000   \n",
            "5  0.000000  0.000000  0.000000  ...  0.028228  0.000000  0.000000  0.002945   \n",
            "6  0.000000  0.004519  0.000000  ...  0.006015  0.000000  0.000000  0.000000   \n",
            "7  0.001902  0.000000  0.001376  ...  0.018234  0.002752  0.001902  0.000000   \n",
            "\n",
            "      youth  youthful    youths      zeal      zone    zounds  \n",
            "0  0.004135  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "1  0.011497  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
            "2  0.011489  0.000000  0.000000  0.000000  0.001609  0.000000  \n",
            "3  0.000000  0.001722  0.001995  0.000000  0.000000  0.000000  \n",
            "4  0.001202  0.000000  0.002256  0.000000  0.000000  0.000000  \n",
            "5  0.010518  0.002130  0.000000  0.002945  0.000000  0.000000  \n",
            "6  0.003362  0.000000  0.000000  0.000000  0.000000  0.003787  \n",
            "7  0.005095  0.004128  0.000000  0.000000  0.000000  0.003189  \n",
            "\n",
            "[8 rows x 11048 columns]\n"
          ]
        }
=======
>>>>>>> Stashed changes
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
<<<<<<< Updated upstream
        "outputId": "64064cb1-c521-4cbf-e5ad-e484dd968e1f"
      },
      "source": [
        "document = 6\n",
        "print(\"25 most important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(sw_free_tf_idf_dt_matrix.iloc[:, np.argsort(sw_free_tf_idf_dt_matrix.loc[document])[::-1]].iloc[document][:25])\n",
        "\n",
        "print(\"25 least important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(sw_free_tf_idf_dt_matrix.iloc[:, np.argsort(sw_free_tf_idf_dt_matrix.loc[document])[::-1]].iloc[document][-25:])"
      ],
      "execution_count": 14,
=======
        "id": "97woQ18ssK8r",
        "outputId": "aabf6d6f-f422-46b7-b230-8a9ae5509ae3"
      },
>>>>>>> Stashed changes
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25 most important terms for document othello.xml\n",
            "iago            0.542255\n",
            "othello         0.506104\n",
            "cassio          0.382591\n",
            "desdemona       0.346441\n",
            "emilia          0.207864\n",
            "roderigo        0.156651\n",
            "thou            0.086619\n",
            "brabantio       0.070794\n",
            "lodovico        0.066276\n",
            "moor            0.064270\n",
            "venice          0.059331\n",
            "shall           0.058348\n",
            "good            0.055340\n",
            "montano         0.054225\n",
            "tis             0.051130\n",
            "come            0.050528\n",
            "let             0.049927\n",
            "lord            0.048723\n",
            "thy             0.047520\n",
            "love            0.046919\n",
            "ll              0.045716\n",
            "handkerchief    0.045188\n",
            "thee            0.045114\n",
            "know            0.043310\n",
            "bianca          0.042175\n",
            "Name: 6, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "document = 6\n",
        "print(\"25 most important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(sw_free_tf_idf_dt_matrix.iloc[:, np.argsort(sw_free_tf_idf_dt_matrix.loc[document])[::-1]].iloc[document][:25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25 least important terms for document othello.xml\n",
            "overhear        0.0\n",
            "outbreak        0.0\n",
            "outbrave        0.0\n",
            "ousel           0.0\n",
            "ourself         0.0\n",
            "ounce           0.0\n",
            "ought           0.0\n",
            "outrun          0.0\n",
            "outside         0.0\n",
            "outstare        0.0\n",
            "outstretched    0.0\n",
            "outstrike       0.0\n",
            "outswear        0.0\n",
            "outwardly       0.0\n",
            "outwork         0.0\n",
            "overbear        0.0\n",
            "overbold        0.0\n",
            "overborne       0.0\n",
            "overcame        0.0\n",
            "overcast        0.0\n",
            "overcharged     0.0\n",
            "overcome        0.0\n",
            "overdone        0.0\n",
            "overflown       0.0\n",
            "1992            0.0\n",
            "Name: 6, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"25 least important terms for document\", shakespeare_df.iloc[document]['book'])\n",
        "print(sw_free_tf_idf_dt_matrix.iloc[:, np.argsort(sw_free_tf_idf_dt_matrix.loc[document])[::-1]].iloc[document][-25:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-lBaRWcsK8s"
      },
      "source": [
        "It's much better now, isn't it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou53w9tCsK8s"
      },
      "source": [
        "Try to play with the previous code, change the document to see how the different weightings affect their representation or to use a different corpus from the ones included in NLTK"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "bag_of_words.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
